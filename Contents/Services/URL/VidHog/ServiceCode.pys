import re, urlparse, cgi, time, urllib, urllib2from datetime import datefrom BeautifulSoup import BeautifulSoup	USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_2) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/534.51.22'def NormalizeURL(url):	#Log("*********** In VidhHog normalizeURL")		# Deal with special providerInfo URL built up by plugin to return	# info about this provider. For all other normal URLs, do nothing. 	if ("providerinfo" in url):			try:			show = Prefs["show_vidhog"]		except Exception, ex:			show = False				if (show):			return url + "&visible=true"		else:			return url				else:		return url	def MetadataObjectForURL(url): 	#Log('In MetadataObjectForURL for VidHog (' + url + ')')		# LMWT Plugin should have access to info about this URL if user used plugin to launch video.	video = LMWTGetVideoClipObjectFromMediaInfo(url)	if video is None:			video = VideoClipObject(			title = 'VidHog Redirect Page',			summary = 'VidHog Redirect Page',			thumb = None,		)		return video	def MediaObjectsForURL(url):	#Log('In MediaObjectsForURL for MovShare (' + url + ')')		return [		MediaObject(			parts = [PartObject(key=Callback(PlayVideo, url=url))],		)	]	@indirect	def PlayVideo(url):	# Page flow from start to video is: 	#	- Initial Page	#	- Countdown Page	#	- Video Link Page	#	# This plugin treats the pages as a two step process where each step can be carried	# out indepedently or one after the other. 	# 	# - To run this a single step, pass in the video URL.	# - To stop after the timer has been initialised and return the URL of the video link page, 	#   append nowait=true to the query string.	# - To retrieve the video after the timer has elapsed, pass in the URL returned by calling this	#   function with nowait=true.		#Log("*********************************************************************")		stage1 = True	stage2 = True		# Work out what parts of the process we need to run.	if ("op=download2" in url):			# Only intersted in second part of process as passed in URL is for Video Link page.		# Note that it's expected that the correct delay has been observed by whoever's passing		# in this URL.		stage1 = False		stage2_URL = url			if ("nowait=true" in url):			# Caller doesn't want us to wait if countdown page has a delay.		stage2 = False				# Remove arg from url.		url_parts = urlparse.urlparse(url)		url_parts =  urlparse.ParseResult(url_parts.scheme, url_parts.netloc, url_parts.path, "", "", "")		url = url_parts.geturl()				if (stage1):			# Deal with initial page.		try:			request = urllib2.Request(url)			request.add_header('User-agent', USER_AGENT)			response = urllib2.urlopen(request)					#Log("Requesting: " + url)			soup = BeautifulSoup(response.read())						provider_url = response.geturl()					except Exception, ex:			return LogProviderError("Error whilst retrieving initial provider page (" + url + ")", ex)					#Log(str(soup))				# Look for any errors from provider.		errors = soup.find('font',{ 'class':'err'})		if (errors is not None):			return LogProviderError("Provider reachable but has returned following error: " + errors.string)				# Extract out these form elements...		formElems = ['op', 'id', 'down_direct', 'method_free', 'method_premium', 'referer', 'rand']		params = {}			try:			for formElem in formElems:				formElemVal =  soup.find('input', {'name' : formElem })['value']				params[formElem] = formElemVal		except Exception, ex:			return LogProviderError("Error whilst retrieving information to go from intial page to countdown page", ex)					# Extract out delay to wait.		try:			delay = int(soup.find('span', id='countdown_str').span.string)		except (Exception, ex):			return LogProviderError("Delay not found on download page. Has something changed?", ex)					#Log("Delay: " + str(delay))			# Create a stage 2 URL. This will be broken down again for stage 2.		stage2_URL = provider_url + "?" + urllib.urlencode(params)				#Log("Stage 2 url: " + stage2_URL)		if (not stage2):				ret = []			ret.append(				MediaObject(					parts = [PartObject(key=stage2_URL, duration=delay)],				)			)			  		return ret	  			  	else:	  				# Looks like the page is happy for us to do the waiting.... so wait.			time.sleep(delay)			pass		if (stage2):				# Breakdown stage2 URL to get params back.		url_parts = urlparse.urlparse(stage2_URL)		#Log(str(url_parts))				params = cgi.parse_qsl(url_parts.query)				# Remove query string arguments we added to form URL to get form URL back.		url_parts =  urlparse.ParseResult(url_parts.scheme, url_parts.netloc, url_parts.path, "", "", "")		#Log(str(url_parts))		form_url = url_parts.geturl()				#Log("*********************************************************************")		#Log("*********************************************************************")		#Log("Params:" + str(params))		#Log("Form URL:" + form_url)				# Submit form.		request = urllib2.Request(form_url,  urllib.urlencode(params))		request.add_header('User-agent', USER_AGENT)		request.add_header('Referer', form_url)		response = urllib2.urlopen(request)				soup = BeautifulSoup(response.read())		#Log(str(soup))				# Extract out video URL.		final_url = soup.find('a', { 'id':'player'})['href']		Log(final_url)				oc = ObjectContainer(			objects = [				VideoClipObject(					items = [						MediaObject(							parts = [PartObject(key=final_url)]						)					]				)			]		)			# Might as well set a sensible user agent string.		oc.user_agent = USER_AGENT				return oc			def LogProviderError(msg="", ex=None):	Log("************************** PROVIDER ERROR: " + msg)	return []